{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f99fb9e",
   "metadata": {},
   "source": [
    "# TensorFlow EffAxNet 3D Demo\n",
    "This notebook demonstrates how to instantiate and train the 3D Efficient Axial Network using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a97d2e",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Ensure TensorFlow 2.13+ with 3D support (GPU recommended). Import the EffAxNet constructors from `axiom`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ec6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from axiom.tf.models import EffAxNetV1\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f739f0",
   "metadata": {},
   "source": [
    "## Build a Volumetric Backbone\n",
    "Creating a 3D EffAxNet feature extractor works the same wayâ€”set `variant=\"3d\"` and request pooled outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef689e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(13)\n",
    "\n",
    "backbone = EffAxNetV1(\n",
    "    variant=\"3d\",\n",
    "    include_top=False,\n",
    "    pooling=\"avg\",\n",
    "    input_shape=(64, 64, 64, 1),\n",
    ")\n",
    "\n",
    "backbone.summary(line_length=100, expand_nested=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f7a33",
   "metadata": {},
   "source": [
    "## Attach a Segmentation/Class Head\n",
    "For volumetric classification, add dense layers. For segmentation tasks, replace the head with 3D convs or UNet-style decoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.trainable = False\n",
    "\n",
    "inputs = backbone.input\n",
    "x = keras.layers.Dense(256, activation=\"relu\")(backbone.output)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "outputs = keras.layers.Dense(4, activation=\"softmax\", name=\"lesion_logits\")(x)\n",
    "model = keras.Model(inputs, outputs, name=\"effaxnet3d_transfer\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d179f64",
   "metadata": {},
   "source": [
    "## Smoke-Test Training Step\n",
    "Use randomly generated volumetric data to validate that the model compiles and trains. Replace this with real DICOM/NIfTI pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_volumes = tf.random.normal([8, 64, 64, 64, 1])\n",
    "dummy_labels = tf.random.uniform([8], minval=0, maxval=4, dtype=tf.int32)\n",
    "\n",
    "model.fit(dummy_volumes, dummy_labels, batch_size=2, epochs=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d480fe2",
   "metadata": {},
   "source": [
    "## Fine-Tune Selected Blocks\n",
    "3D models are memory heavy. Unfreeze carefully and consider mixed precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14287b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in backbone.layers[-15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=2e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(dummy_volumes, dummy_labels, batch_size=2, epochs=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece3542",
   "metadata": {},
   "source": [
    "## Persist Checkpoints\n",
    "Save the trained weights and rebuild the backbone later using the `include_weights` shortcut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"effaxnet3d_transfer.weights.h5\"\n",
    "model.save_weights(checkpoint_path)\n",
    "\n",
    "reloaded_backbone = EffAxNetV1(\n",
    "    variant=\"3d\",\n",
    "    include_top=False,\n",
    "    pooling=\"avg\",\n",
    "    input_shape=(64, 64, 64, 1),\n",
    "    include_weights=checkpoint_path,\n",
    ")\n",
    "\n",
    "print(\"Reloaded backbone output shape:\", reloaded_backbone.output_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94328f1",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Swap dummy volumes with your medical dataset (e.g., `tfio.IODataset.from_parquet`, NIfTI readers, etc.).\n",
    "- Convert the backbone to mixed precision with `tf.keras.mixed_precision.set_global_policy('mixed_float16')` for speed.\n",
    "- Export to SavedModel or ONNX for deployment once fine-tuning is complete."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
